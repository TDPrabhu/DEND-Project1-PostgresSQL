## Introduction
The Purpose of this database is to store the data generated from the log file, which will be useful for generating the report based on user 
input.


### Example: 
##### 1) How many users have subscribed (i.e. paid user) and listening to the songs and how many have not? 
##### 2)Listing the number users based on the Geographical location. 
##### 3) Most liked songs and artists by user’s preference

## Description
Database is designed with fact table and multiple dimension tables with required constraints on the column.

Python script etl.py is used for extracting the data from the files provided, transform and store the data in the database. 
The script uses pandas, psycopg2 package to data munging and connect to the database. It does all the required validation like checking 
for the duplicate before inserting the data into the DB.

### Table Creation
Tables are created by executing the Python script create_tables.py.
The create_tables.py in returns call the sql_queries.py which has all the DDL and DML statements in it.

### ETL Pipeline
Python etl.py is used to extract & transform the data from the file provided. It establishes the connection to the DB, then it extracts the required information from the files mentioned in the path and stores the data in to the appropriate tables. It checks for the duplicate before inserting the record into the tables.
The code is modularized and provided all the comments.

## Project Structure
#####  /log_data - A folder that contains files of log files in JSON format generated by this event simulator based on the songs in the dataset above. 
#####  /song_data - Each file is in JSON format and contains metadata about a song and the artist of that song. 
#####  etl.ipynb - jupyter notebook that helps to know step by step what etl.py does 
#####  create_tables.py - This script will drop old tables and re-create new tables 
#####  etl.py - Script will read JSON every file contained in data / folder, parse them, transform them and insert the data

## Steps to execute the code
1. Open a new terminal
2. First execute the create_tables.py.
python create_tables.py
3. Next Execute the etl.py
python etl.py
Re run the create_tables.py, whenever you do the change to sql_queries.py or before you execute the etl.py
Example query for song play analysis select count(user_id), level from songsplay group by level;
